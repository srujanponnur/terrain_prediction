{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./TrainingData/\"\n",
    "val_subject_number = 5\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for filename in os.listdir(PATH):\n",
    "    files.append(filename)\n",
    "files = sorted(files, key = lambda x: (int(x.split('_')[1]),int(x.split('_')[2]), x.split('_')[4] ))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the value count of the window (15) and reducing the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windows(d, w, t):\n",
    "  r = np.arange(len(d))\n",
    "  # print(r)\n",
    "  s = r[::t]\n",
    "  # print(s)\n",
    "  z = list(zip(s, s + w))\n",
    "  f = '{0[0]}:{0[1]}'.format\n",
    "  g = lambda t: d.iloc[t[0]:t[1]]\n",
    "  ranges = list(map(f,z))\n",
    "  # print(ranges[-1])\n",
    "  return ranges, pd.concat(map(g, z), keys=map(f, z))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatinating features and timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\NCSU\\spring_2023\\Neural Networks\\terrain_prediction\\preprocessing.ipynb Cell 7\u001b[0m in \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m train_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([x_combined, y_combined], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m train_df \u001b[39m=\u001b[39m train_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m8\u001b[39m])  \u001b[39m# Dropping the time stamp\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m Y\u001b[39m.\u001b[39;49mextend(train_df[\u001b[39m9\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues[\u001b[39m0\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# print(train_df.drop(columns=[9]).values[0])\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m X\u001b[39m.\u001b[39mextend(train_df\u001b[39m.\u001b[39mdrop(columns\u001b[39m=\u001b[39m[\u001b[39m9\u001b[39m])\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for i in range(0, len(files), 4):\n",
    "    x_time, x, y_time, y = files[i: i + 4]\n",
    "    x_time_df = pd.read_csv(PATH + x_time , header=None)\n",
    "    x_df = pd.read_csv(PATH + x , header=None)\n",
    "    x_combined = pd.concat([x_time_df, x_df], axis=1, ignore_index=True)\n",
    "    x_combined = x_combined.loc[range(1,len(x_combined), 4)].reset_index()  # down sampled the frequency\n",
    "    # print(x_combined.shape)\n",
    "\n",
    "    y_time_df = pd.read_csv(PATH + y_time , header=None)\n",
    "    y_df = pd.read_csv(PATH + y , header=None)\n",
    "    y_combined = pd.concat([y_time_df, y_df], axis=1, ignore_index=True)\n",
    "    # print(y_combined.shape)\n",
    "    train_df = pd.concat([x_combined, y_combined], axis=1, ignore_index=True)\n",
    "    train_df = train_df.drop(columns=[0, 1, 8])  # Dropping the time stamp\n",
    "    Y.extend(train_df[9].values)\n",
    "    print(train_df.drop(columns=[9]).values[0])\n",
    "    X.extend(train_df.drop(columns=[9]).values[0])\n",
    "    overlap = 15\n",
    "    # print(train_df)\n",
    "    # ranges, windows_df = windows(train_df, 30, overlap)\n",
    "    # # print(windows_df.shape)\n",
    "    # for ran in ranges:\n",
    "    #     l,r = ran.split(':')\n",
    "    #     df_range = windows_df.iloc[int(l): int(r)]\n",
    "    #     if int(r) > len(windows_df):\n",
    "    #         break\n",
    "    #     y_values = df_range[9].values\n",
    "    #     x_values = df_range.drop(columns=[9]).values\n",
    "    #     print(x_values)\n",
    "    #     X.append(x_values)\n",
    "    #     # print(Counter(list(y_values)).most_common(1)[0][0])\n",
    "    #     Y.append(Counter(list(y_values)).most_common(1)[0][0])\n",
    "print(len(X), len(Y))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weights that compensate for the imbalance distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight  = compute_class_weight(class_weight = 'balanced', classes = np.unique(Y), y = np.array(Y))\n",
    "weight = torch.tensor(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:746: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  array = np.asarray(array, order=order, dtype=dtype)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'any'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\NCSU\\spring_2023\\Neural Networks\\terrain_prediction\\preprocessing.ipynb Cell 11\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(X, Y,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                                                     stratify\u001b[39m=\u001b[39;49mY, \n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X16sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                                                     test_size\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2441\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2437\u001b[0m         CVClass \u001b[39m=\u001b[39m ShuffleSplit\n\u001b[0;32m   2439\u001b[0m     cv \u001b[39m=\u001b[39m CVClass(test_size\u001b[39m=\u001b[39mn_test, train_size\u001b[39m=\u001b[39mn_train, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m-> 2441\u001b[0m     train, test \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(cv\u001b[39m.\u001b[39;49msplit(X\u001b[39m=\u001b[39;49marrays[\u001b[39m0\u001b[39;49m], y\u001b[39m=\u001b[39;49mstratify))\n\u001b[0;32m   2443\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(\n\u001b[0;32m   2444\u001b[0m     chain\u001b[39m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2445\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m arrays\n\u001b[0;32m   2446\u001b[0m     )\n\u001b[0;32m   2447\u001b[0m )\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2022\u001b[0m, in \u001b[0;36mStratifiedShuffleSplit.split\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1988\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msplit\u001b[39m(\u001b[39mself\u001b[39m, X, y, groups\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1989\u001b[0m     \u001b[39m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \n\u001b[0;32m   1991\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2020\u001b[0m \u001b[39m    to an integer.\u001b[39;00m\n\u001b[0;32m   2021\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2022\u001b[0m     y \u001b[39m=\u001b[39m check_array(y, ensure_2d\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, dtype\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   2023\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39msplit(X, y, groups)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:800\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m             \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m         )\n\u001b[0;32m    799\u001b[0m     \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[1;32m--> 800\u001b[0m         _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39;49mforce_all_finite \u001b[39m==\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    802\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_samples \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    803\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:121\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[39m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39melif\u001b[39;00m X\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nan:\n\u001b[1;32m--> 121\u001b[0m     \u001b[39mif\u001b[39;00m _object_dtype_isnan(X)\u001b[39m.\u001b[39;49many():\n\u001b[0;32m    122\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mInput contains NaN\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'any'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,\n",
    "                                                    stratify=Y, \n",
    "                                                    test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 13054, 3: 3478, 2: 448, 1: 920})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.615648  ,  8.477261  , 13.4497    ,  7.79267   , -0.2387123 ,\n",
       "        -0.3467662 ],\n",
       "       [-7.819409  ,  3.16739   ,  8.919365  , -3.38206   , -1.772744  ,\n",
       "        -0.2648882 ],\n",
       "       [-6.231173  ,  8.425428  , 14.94341   , -2.877805  ,  0.9527063 ,\n",
       "         0.5746796 ],\n",
       "       [-1.717818  ,  9.547422  ,  6.591871  , -1.330105  , -1.409305  ,\n",
       "        -0.467174  ],\n",
       "       [-2.111716  ,  9.098293  ,  3.350611  , -0.6741492 , -1.329205  ,\n",
       "        -0.4670816 ],\n",
       "       [-2.260614  ,  8.517343  ,  0.09903866, -1.072398  , -1.317475  ,\n",
       "        -0.2679185 ],\n",
       "       [-4.217178  ,  9.443285  , -1.412576  , -2.434406  , -0.4838025 ,\n",
       "         0.3650663 ],\n",
       "       [ 3.102272  , 16.31312   , -1.552971  , -4.180005  , -1.568144  ,\n",
       "         0.7121762 ],\n",
       "       [-4.024575  , 11.83685   , 17.43845   , -1.564761  ,  0.06709305,\n",
       "         0.1678368 ],\n",
       "       [-2.769921  ,  1.520739  ,  8.888709  ,  2.987751  , -0.2146547 ,\n",
       "        -1.07917   ],\n",
       "       [ 3.870735  ,  0.9826841 , 10.15286   ,  6.429614  ,  2.449326  ,\n",
       "        -0.5126566 ],\n",
       "       [ 0.03672651,  9.384471  , 13.21158   ,  7.692378  , -0.1359672 ,\n",
       "        -0.5416323 ],\n",
       "       [-4.643125  ,  0.3234583 , 10.10552   , -4.224169  , -0.585839  ,\n",
       "         0.2638898 ],\n",
       "       [-5.670831  ,  5.995624  , 16.00136   , -2.656202  ,  1.026042  ,\n",
       "         0.5075512 ],\n",
       "       [ 2.532752  ,  9.789009  ,  6.290661  , -1.311808  , -0.9370821 ,\n",
       "        -0.3887008 ],\n",
       "       [-2.615648  ,  8.477261  , 13.4497    ,  7.79267   , -0.2387123 ,\n",
       "        -0.3467662 ],\n",
       "       [-7.819409  ,  3.16739   ,  8.919365  , -3.38206   , -1.772744  ,\n",
       "        -0.2648882 ],\n",
       "       [-6.231173  ,  8.425428  , 14.94341   , -2.877805  ,  0.9527063 ,\n",
       "         0.5746796 ],\n",
       "       [-1.717818  ,  9.547422  ,  6.591871  , -1.330105  , -1.409305  ,\n",
       "        -0.467174  ],\n",
       "       [-2.111716  ,  9.098293  ,  3.350611  , -0.6741492 , -1.329205  ,\n",
       "        -0.4670816 ],\n",
       "       [-2.260614  ,  8.517343  ,  0.09903866, -1.072398  , -1.317475  ,\n",
       "        -0.2679185 ],\n",
       "       [-4.217178  ,  9.443285  , -1.412576  , -2.434406  , -0.4838025 ,\n",
       "         0.3650663 ],\n",
       "       [ 3.102272  , 16.31312   , -1.552971  , -4.180005  , -1.568144  ,\n",
       "         0.7121762 ],\n",
       "       [-4.024575  , 11.83685   , 17.43845   , -1.564761  ,  0.06709305,\n",
       "         0.1678368 ],\n",
       "       [-2.769921  ,  1.520739  ,  8.888709  ,  2.987751  , -0.2146547 ,\n",
       "        -1.07917   ],\n",
       "       [ 3.870735  ,  0.9826841 , 10.15286   ,  6.429614  ,  2.449326  ,\n",
       "        -0.5126566 ],\n",
       "       [ 0.03672651,  9.384471  , 13.21158   ,  7.692378  , -0.1359672 ,\n",
       "        -0.5416323 ],\n",
       "       [-4.643125  ,  0.3234583 , 10.10552   , -4.224169  , -0.585839  ,\n",
       "         0.2638898 ],\n",
       "       [-5.670831  ,  5.995624  , 16.00136   , -2.656202  ,  1.026042  ,\n",
       "         0.5075512 ],\n",
       "       [ 2.532752  ,  9.789009  ,  6.290661  , -1.311808  , -0.9370821 ,\n",
       "        -0.3887008 ]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\NCSU\\spring_2023\\Neural Networks\\terrain_prediction\\preprocessing.ipynb Cell 14\u001b[0m in \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/NCSU/spring_2023/Neural%20Networks/terrain_prediction/preprocessing.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m clf \u001b[39m=\u001b[39m RandomForestClassifier(n_estimators \u001b[39m=\u001b[39;49m \u001b[39m500\u001b[39;49m, max_depth \u001b[39m=\u001b[39;49m \u001b[39m4\u001b[39;49m, max_features \u001b[39m=\u001b[39;49m \u001b[39m3\u001b[39;49m, bootstrap \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m, random_state \u001b[39m=\u001b[39;49m \u001b[39m18\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:327\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m issparse(y):\n\u001b[0;32m    326\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 327\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    328\u001b[0m     X, y, multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mDTYPE\n\u001b[0;32m    329\u001b[0m )\n\u001b[0;32m    330\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    331\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[0;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[0;32m    965\u001b[0m     X,\n\u001b[0;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[0;32m    967\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[0;32m    968\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    969\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[0;32m    970\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    971\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[0;32m    972\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[0;32m    973\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[0;32m    974\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[0;32m    975\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[0;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    977\u001b[0m )\n\u001b[0;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[0;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:794\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    789\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    790\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUnable to convert array of bytes/strings \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    791\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39minto decimal numbers with dtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    792\u001b[0m         ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m allow_nd \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m--> 794\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    795\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound array with dim \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m expected <= 2.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    796\u001b[0m         \u001b[39m%\u001b[39m (array\u001b[39m.\u001b[39mndim, estimator_name)\n\u001b[0;32m    797\u001b[0m     )\n\u001b[0;32m    799\u001b[0m \u001b[39mif\u001b[39;00m force_all_finite:\n\u001b[0;32m    800\u001b[0m     _assert_all_finite(array, allow_nan\u001b[39m=\u001b[39mforce_all_finite \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mallow-nan\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators = 500, max_depth = 4, max_features = 3, bootstrap = True, random_state = 18).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
