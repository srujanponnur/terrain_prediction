{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, InputLayer, Dropout, Conv1D, MaxPool1D, Input, LayerNormalization, Reshape, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.python.keras import regularizers\n",
    "from sklearn.utils import class_weight\n",
    "import statistics as st\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import genfromtxt\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from numpy import dstack\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from tensorflow.keras import utils as np_utils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_PATH = \"dataset/ECE542_sp2022_Project_TerrainRecognition/\"  #'/content/drive/MyDrive/ECE542/CompetitiveProject/ECE542_sp2022_Project_TerrainRecognition'\n",
    "PATH = S_PATH +'/TrainingData/'\n",
    "TEST_PATH = S_PATH + \"./TestData/\"\n",
    "test_subject = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for filename in os.listdir(PATH):\n",
    "    files.append(filename)\n",
    "files = sorted(files, key = lambda x: (int(x.split('_')[1]),int(x.split('_')[2]), x.split('_')[4] ))\n",
    "files_train = list(filter(lambda x: int(x.split('_')[1]) not in  [test_subject], files))\n",
    "files_train = [os.path.join(PATH, i) for i in files_train]\n",
    "files_test = list(filter(lambda x: int(x.split('_')[1]) == test_subject, files))\n",
    "files_test = [os.path.join(PATH, i) for i in files_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_train_x_path = files_train[1::4]\n",
    "files_test_x_path = files_test[1::4]\n",
    "files_train_y_path = files_train[3::4]\n",
    "files_test_y_path = files_test[3::4]\n",
    "files_train_x = [pd.read_csv(i) for i in files_train_x_path]\n",
    "files_test_x = [pd.read_csv(i) for i in files_test_x_path]\n",
    "files_train_y = [pd.read_csv(i) for i in files_train_y_path]\n",
    "files_test_y = [pd.read_csv(i) for i in files_test_y_path]\n",
    "# files_train_x, files_test_x, files_train_y, files_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_splits(all_files_paths, all_files):\n",
    "    continue_loop = True\n",
    "    threshold = 0.005\n",
    "    all_files = pd.concat(all_files)\n",
    "    _, files_split_dist = np.unique(all_files, return_counts=True)\n",
    "    files_split_dist = np.divide(files_split_dist, np.max(files_split_dist))\n",
    "    while continue_loop:\n",
    "        random_seed = np.random.randint(0, (2 ** 31) - 1)\n",
    "        np.random.seed(random_seed)\n",
    "        random.seed(random_seed)\n",
    "        files_train_y_split_1 = random.sample(all_files_paths, int(len(all_files_paths) * 0.8))\n",
    "        files_train_y_split_2 = [i for i in all_files_paths if i not in files_train_y_split_1]\n",
    "        files_split_1_val = pd.concat([pd.read_csv(i , header=None) for i in files_train_y_split_1])\n",
    "        files_split_2_val = pd.concat([pd.read_csv(i , header=None) for i in files_train_y_split_2])\n",
    "        _, files_split_1_dist = np.unique(files_split_1_val, return_counts=True)\n",
    "        files_split_1_dist = np.divide(files_split_1_dist, np.max(files_split_1_dist))\n",
    "        _, files_split_2_dist = np.unique(files_split_2_val, return_counts=True)\n",
    "        files_split_2_dist = np.divide(files_split_2_dist, np.max(files_split_2_dist))\n",
    "        if ((files_split_dist[0] - threshold <= files_split_1_dist[0] <= files_split_dist[0] + threshold) and\n",
    "            (files_split_dist[1] - threshold <= files_split_1_dist[1] <= files_split_dist[1] + threshold) and\n",
    "            (files_split_dist[2] - threshold <= files_split_1_dist[2] <= files_split_dist[2] + threshold) and\n",
    "            (files_split_dist[3] - threshold <= files_split_1_dist[3] <= files_split_dist[3] + threshold) and\n",
    "            (files_split_dist[0] - threshold <= files_split_2_dist[0] <= files_split_dist[0] + threshold) and\n",
    "            (files_split_dist[1] - threshold <= files_split_2_dist[1] <= files_split_dist[1] + threshold) and\n",
    "            (files_split_dist[2] - threshold <= files_split_2_dist[2] <= files_split_dist[2] + threshold) and\n",
    "            (files_split_dist[3] - threshold <= files_split_2_dist[3] <= files_split_dist[3] + threshold)):\n",
    "                print(files_split_1_dist, files_split_2_dist, files_split_dist)\n",
    "                return sorted(files_train_y_split_1), sorted(files_train_y_split_2), random_seed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.         0.05549903 0.07357915 0.21037401] [1.         0.05648564 0.0787299  0.21565654] [1.         0.0557347  0.07478412 0.21162566]\n"
     ]
    }
   ],
   "source": [
    "y_train_files, y_val_files, random_seed = generate_splits(files_train_y_path, files_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_file_names = [\"_\".join(i.split(\"/\")[-1].split(\"__\")[: -1]) for i in y_train_files]\n",
    "y_val_file_names = [\"_\".join(i.split(\"/\")[-1].split(\"__\")[: -1]) for i in y_val_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_files = sorted([i for i in files_train_x_path if \"_\".join(i.split(\"/\")[-1].split(\"__\")[: -1]) in y_train_file_names])\n",
    "x_val_files = sorted([i for i in files_train_x_path if \"_\".join(i.split(\"/\")[-1].split(\"__\")[: -1]) in y_val_file_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List):\n",
    "    occurence_count = Counter(List)\n",
    "    return occurence_count.most_common(1)[0][0]\n",
    "\n",
    "\n",
    "def mode(a, axis=0):\n",
    "    scores = np.unique(np.ravel(a))       # get ALL unique values\n",
    "    testshape = list(a.shape)\n",
    "    testshape[axis] = 1\n",
    "    oldmostfreq = np.zeros(testshape)\n",
    "    oldcounts = np.zeros(testshape)\n",
    "\n",
    "    for score in scores:\n",
    "        template = (a == score)\n",
    "        counts = np.expand_dims(np.sum(template, axis),axis)\n",
    "        mostfrequent = np.where(counts > oldcounts, score, oldmostfreq)\n",
    "        oldcounts = np.maximum(counts, oldcounts)\n",
    "        oldmostfreq = mostfrequent\n",
    "\n",
    "    return mostfrequent, oldcounts\n",
    "\n",
    "\n",
    "def preprocessing(x_files, y_files, window_size=30):\n",
    "    final_x = []\n",
    "    final_y = []\n",
    "    for i in range(len(y_files)):\n",
    "        X_df = pd.read_csv(x_files[i])\n",
    "        y_df = pd.read_csv(y_files[i])\n",
    "        a = []\n",
    "        for i in range(0, len(y_df)):\n",
    "            a += [y_df['0'][i]] * 4\n",
    "        upsampled_df = pd.DataFrame(a)\n",
    "        diff = X_df.shape[0] - upsampled_df.shape[0]\n",
    "        X_df = X_df.iloc[:-diff,:]\n",
    "\n",
    "        sc=StandardScaler()\n",
    "        X_df=sc.fit_transform(X_df)\n",
    "\n",
    "        x_arr=[]\n",
    "        y_arr=[]\n",
    "\n",
    "        for j in range(len(X_df)-30):\n",
    "            x_arr.append(X_df[j: (j + window_size)]) \n",
    "            y_arr.append(mode(upsampled_df.iloc[j: (j + window_size)])[0])\n",
    "        final_x.append(np.array(x_arr))\n",
    "        final_y.append(np.array(y_arr).reshape(-1,1))\n",
    "    return final_x, final_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, trainY = preprocessing(x_train_files, y_train_files)\n",
    "trainX, trainY = np.concatenate(trainX), np.concatenate(trainY)\n",
    "valX, valY = preprocessing(x_train_files, y_train_files)\n",
    "valX, valY = np.concatenate(valX), np.concatenate(valY)\n",
    "testX, testY = preprocessing(files_test_x_path, files_test_y_path)\n",
    "testX, testY = np.concatenate(testX), np.concatenate(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(trainY), y=trainY.ravel())\n",
    "label_weights = {i:label_weights[i] for i in range(len(label_weights))} # Create dictionary\n",
    "print(label_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hot_y_train = np_utils.to_categorical(trainY)\n",
    "hot_y_val = np_utils.to_categorical(valY)\n",
    "# hot_y_test = np_utils.to_categorical(testY)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simpleLSTM(timestep, features, n_outputs, hidden_units=125):\n",
    "    model_LSTM = Sequential()\n",
    "    model_LSTM.add(InputLayer(input_shape=(timestep, features)))\n",
    "    model_LSTM.add(LSTM(units=hidden_units, activation='relu'))\n",
    "    model_LSTM.add(Dropout(0.5))\n",
    "    model_LSTM.add(Dense(units = hidden_units, activation = 'relu'))\n",
    "    model_LSTM.add(Dense(n_outputs, activation='softmax')) # output layer\n",
    "    return model_LSTM\n",
    "\n",
    "\n",
    "def simpleLSTM2(timestep, features, n_outputs, hidden_units=125):\n",
    "    x_in = Input(shape=(timestep, features))\n",
    "    x = LSTM(units=hidden_units, activation='relu', kernel_regularizer=l2(0.001), recurrent_regularizer=l2(0.001), bias_regularizer=l2(0.001))(x_in)\n",
    "    x = LayerNormalization()(x) \n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(units = hidden_units, activation = 'relu', kernel_regularizer=l2(0.001), bias_regularizer=l2(0.001))(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dense(n_outputs, activation='softmax')(x)\n",
    "    model_LSTM = Model(inputs=x_in, outputs=x)\n",
    "    return model_LSTM\n",
    "\n",
    "\n",
    "\n",
    "def LSTMConv(timestep, features, n_outputs, hidden_units=125, filters=64, kernel_size=1):\n",
    "    x_in = Input(shape=(timestep, features))\n",
    "    x = LSTM(units=hidden_units, activation='relu')(x_in)\n",
    "    x = LayerNormalization()(x) \n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Reshape((1, 1, hidden_units))(x)\n",
    "    print(x.shape)\n",
    "    x = Conv1D(filters=filters, kernel_size=kernel_size, activation='relu', padding='same')(x) \n",
    "    x = Flatten()(x) \n",
    "    x = Dense(units=hidden_units, activation='relu')(x)\n",
    "    x = LayerNormalization()(x)\n",
    "    x = Dense(n_outputs, activation='softmax')(x)\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestep, features, n_outputs = trainX.shape[1], trainX.shape[2], 4\n",
    "# model = simpleLSTM(timestep, features, n_outputs, 125)\n",
    "model = simpleLSTM2(timestep, features, n_outputs, 125)\n",
    "# model = LSTMConv(timestep, features, n_outputs, hidden_units=125, filters=64, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model.h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=3, min_lr=0.000001\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, verbose=1),\n",
    "]\n",
    "loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.05)\n",
    "optimizer= Adam(learning_rate=0.001)\n",
    "metrics=['accuracy']\n",
    "model.compile(optimizer, loss, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainX, hot_y_train, epochs = 50, batch_size = 256,\n",
    "                    validation_data = (valX, hot_y_val), class_weight = label_weights,\n",
    "                    verbose = 1, shuffle = True, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'], color='red')\n",
    "plt.plot(history.history['val_accuracy'], color='blue')\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'], color='red')\n",
    "plt.plot(history.history['val_loss'], color='blue')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = r\"C:\\Users\\sumuk\\OneDrive\\Desktop\\NCSU_related\\Courses_and_stuff\\Courses_and_stuff\\NCSU_courses_and_books\\ECE_542\\CompetitiveProject\\terrain_prediction\\best_model.h5\"\n",
    "model.load_weights(model_weights)\n",
    "y_pred = model.predict(testX, batch_size = 256, verbose = 1)\n",
    "y_test_bool = np.argmax(y_pred, axis = 1)\n",
    "print(classification_report(testY, y_test_bool))\n",
    "print(confusion_matrix(testY, y_test_bool))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction generation on actual test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_folder = r\"C:\\Users\\sumuk\\OneDrive\\Desktop\\NCSU_related\\Courses_and_stuff\\Courses_and_stuff\\NCSU_courses_and_books\\ECE_542\\CompetitiveProject\\terrain_prediction\\dataset\\ECE542_sp2022_Project_TerrainRecognition\\TestData\"\n",
    "save_folder = r\"C:\\Users\\sumuk\\OneDrive\\Desktop\\NCSU_related\\Courses_and_stuff\\Courses_and_stuff\\NCSU_courses_and_books\\ECE_542\\CompetitiveProject\\Models\\tf_experiments\\6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_dataset_folder, file_name_x, file_name_y, save_name):\n",
    "    input_data = pd.read_csv(os.path.join(test_dataset_folder, file_name_x))\n",
    "    sc = StandardScaler()\n",
    "    df = sc.fit_transform(input_data)\n",
    "    y_frame = pd.read_csv(os.path.join(test_dataset_folder, file_name_y))\n",
    "    addl_rows = y_frame.shape[0] * 4 - df.shape[0] + 30\n",
    "    addl_rows_df = pd.DataFrame(df[-addl_rows:])\n",
    "    df = pd.DataFrame(df)\n",
    "    df = df.append(addl_rows_df)\n",
    "    X_values = []\n",
    "    for i in range(0, len(df) - 30, 1):\n",
    "        value = df.iloc[i:(i + 30)].values\n",
    "        X_values.append(value)\n",
    "    X_test = np.array(X_values)\n",
    "    y_test = model.predict(X_test, batch_size = 256, verbose = 1)\n",
    "    y_test_class = np.argmax(y_test, axis = 1)\n",
    "    output_actual = []\n",
    "    for i in range(0, y_test_class.shape[0], 4):\n",
    "        a = list(y_test_class[i:i + 4])\n",
    "        output_actual.append(max(a, key = a.count))\n",
    "    y_actual = np.array(output_actual)\n",
    "    print(y_actual.size)\n",
    "    y_series = pd.Series(y_actual)\n",
    "    y_series.to_csv(os.path.join(save_folder, save_name),index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = r\"C:\\Users\\sumuk\\OneDrive\\Desktop\\NCSU_related\\Courses_and_stuff\\Courses_and_stuff\\NCSU_courses_and_books\\ECE_542\\CompetitiveProject\\terrain_prediction\\best_model.h5\"\n",
    "model.load_weights(model_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(model, test_dataset_folder, \"subject_009_01__x.csv\", \"subject_009_01__y_time.csv\", \"subject_009_01__y.csv\")\n",
    "predict(model, test_dataset_folder, \"subject_009_01__x.csv\", \"subject_010_01__y_time.csv\", \"subject_010_01__y.csv\")\n",
    "predict(model, test_dataset_folder, \"subject_009_01__x.csv\", \"subject_011_01__y_time.csv\", \"subject_011_01__y.csv\")\n",
    "predict(model, test_dataset_folder, \"subject_009_01__x.csv\", \"subject_012_01__y_time.csv\", \"subject_012_01__y.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare 2 models (discrepency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_files_folder = r\"C:\\Users\\sumuk\\OneDrive\\Desktop\\NCSU_related\\Courses_and_stuff\\Courses_and_stuff\\NCSU_courses_and_books\\ECE_542\\CompetitiveProject\\Models\\C3.2_submission\"\n",
    "target_files_folder = r\"C:\\Users\\sumuk\\OneDrive\\Desktop\\NCSU_related\\Courses_and_stuff\\Courses_and_stuff\\NCSU_courses_and_books\\ECE_542\\CompetitiveProject\\Results_from_Sai\"\n",
    "predicted_files_folder = r\"C:\\Users\\sumuk\\OneDrive\\Desktop\\NCSU_related\\Courses_and_stuff\\Courses_and_stuff\\NCSU_courses_and_books\\ECE_542\\CompetitiveProject\\Models\\tf_experiments\\6\"\n",
    "# predicted_files_folder = r\"C:\\Users\\sumuk\\OneDrive\\Desktop\\NCSU_related\\Courses_and_stuff\\Courses_and_stuff\\NCSU_courses_and_books\\ECE_542\\CompetitiveProject\\Models\\C3.2_submission\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_files_path = [os.path.join(target_files_folder, i) for i in sorted(os.listdir(target_files_folder))]\n",
    "predicted_files_path = [os.path.join(predicted_files_folder, i) for i in sorted(os.listdir(predicted_files_folder))]\n",
    "target_files = [pd.read_csv(i, header=None) for i in target_files_path]\n",
    "predicted_files = [pd.read_csv(i, header=None) for i in predicted_files_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(i) for i in predicted_files], [len(i) for i in target_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms = []\n",
    "for i, j in zip(target_files, predicted_files):\n",
    "    target_values = list(i.values)\n",
    "    predicted_values = list(j.values)\n",
    "    print(len(target_values), len(predicted_values))\n",
    "    cms.append(confusion_matrix(y_true=target_values, y_pred=predicted_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cms[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BRaTS2021_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
